{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data, vocab\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from utils import execute_and_time, get_device, itos\n",
    "from preprocess import Batch, embedding_param\n",
    "from model import Transformer\n",
    "from optimize import get_default_optimizer, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE = False\n",
    "logger = logging.getLogger()\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "if LOG_FILE:\n",
    "    file_handler = logging.FileHandler('log.out')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler) \n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-20 12:18:42,001 INFO GPU unavailable, using CPU.\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data/'\n",
    "SAMPLE_DATA_PATH = f'{DATA_PATH}sample_data/'\n",
    "PROCESSED_DATA_PATH = f'{DATA_PATH}processed_data/'\n",
    "\n",
    "pre_trained_vector_type = 'glove.6B.200d' \n",
    "batch_size = 64\n",
    "device = get_device()\n",
    "stack_number = 6\n",
    "heads_number = 8\n",
    "fix_length = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 1.44 s, total: 1min 54s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = data.get_tokenizer('spacy')\n",
    "TEXT = data.Field(tokenize=tokenizer, lower=True, eos_token='_eos_', fix_length=fix_length)\n",
    "trn_data_fields = [(\"source\", TEXT), (\"target\", TEXT)]\n",
    "trn, vld = data.TabularDataset.splits(path=f'{SAMPLE_DATA_PATH}',\n",
    "                           train='train_ds.csv', \n",
    "                           validation='valid_ds.csv',\n",
    "                           format='csv', \n",
    "                           skip_header=True, \n",
    "                           fields=trn_data_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-20 12:21:49,080 INFO Loading vectors from .vector_cache/glove.6B.200d.txt.pt\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(trn, vectors=pre_trained_vector_type)\n",
    "vocabulary = TEXT.vocab\n",
    "vocab_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits((trn, vld), \n",
    "                                                  batch_sizes=(batch_size, int(batch_size * 1.6)),\n",
    "                                                  device=device, \n",
    "                                                  sort_key=lambda x: len(x.source),\n",
    "                                                  shuffle=True, \n",
    "                                                  sort_within_batch=False, \n",
    "                                                  repeat=True)\n",
    "train_iter = Batch(train_iter, \"source\", \"target\", vocabulary, device=device)\n",
    "val_iter = Batch(val_iter, \"source\", \"target\", vocabulary, device=device)\n",
    "# train_iter, val_iter = iter(train_iter_tuple), iter(val_iter_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> 4\n",
      "torch.Size([64, 80]) torch.Size([64, 80]) torch.Size([64, 1, 1, 80]) torch.Size([64, 1, 80, 80])\n",
      "source:\n",
      "legendary fifa the a at olivier the riots washington greek jitters while china these egyptian signs a zimbabwe torrential passenger some large canadian heavily each the with u.s a los hermann stocks british the the the a an the scientists bill france spyker a some israel the following the it a more countdown second chinese david residents the insurgency the women former the voters \n",
      "\n",
      "corresponding tensor:\n",
      "tensor([ 5558,  1902,     4,    10,    18, 11089,     4,  3123,   425,   702,\n",
      "         7213,   298,    42,  1617,   823,   852,    10,   559,  4929,  1556,\n",
      "          173,   869,   656,  2858,  1181,     4,    17,    40,    10,   739,\n",
      "        15032,   146,   134,     4,     4,     4,    10,    25,     4,  1108,\n",
      "          395,   197, 19383,    10,   173,   166,     4,   293,     4,    45,\n",
      "           10,    63,  7914,   124,    95,  1091,  1078,     4,  4038,     4,\n",
      "          234,    90,     4,  1153]) \n",
      "\n",
      "target:\n",
      "legend fifa iraq egypt paraguay panis report riots cleaning greece australian adriano china cox mubarak impasse pakistan zimbabwe fresh european change may us venezuela an in a u.s british perez hermann stocks blair zambian third europe # a u.n curtain pulsipher rugbyu saab < sects senior decertification stocks washington bah opposition aging beijing ferrero china rockefeller about museum sri uae women former bangkok belarus \n",
      "\n",
      "corresponding tensor:\n",
      "tensor([ 4040,  1902,    88,   590,  4428, 34325,   231,  3123,  7593,   787,\n",
      "          233,  8851,    42,  2080,  2074,  4072,   181,   559,   929,   103,\n",
      "          716,   150,    49,   892,    25,     8,    10,    40,   134,  6541,\n",
      "        15032,   146,  1251,  2639,   268,   372,     3,    10,   252,  9675,\n",
      "        34765, 48642,  8188,    21, 28090,   361, 40465,   146,   425, 38196,\n",
      "          208,  5433,   346,  6956,    42, 12025,    94,  1675,   341,  2729,\n",
      "          234,    90,  2135,  2276]) \n",
      "\n",
      "tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.uint8)\n",
      "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "batch = next(train_iter)\n",
    "print(type(batch), len(batch))\n",
    "print(batch[0].size(), batch[1].size(), batch[2].size(), batch[3].size())\n",
    "\n",
    "sample_source = batch[0].transpose(1,0)[0]\n",
    "sample_target = batch[1].transpose(1,0)[0]\n",
    "sample_src_mask = batch[2].transpose(1,0)[0]\n",
    "sample_tgt_mask = batch[3].transpose(1,0)[0]\n",
    "\n",
    "\n",
    "print(\"source:\\n%s \\n\\ncorresponding tensor:\\n%s \\n\" %(itos(sample_source, vocabulary), sample_source))\n",
    "print(\"target:\\n%s \\n\\ncorresponding tensor:\\n%s \\n\" %(itos(sample_target, vocabulary), sample_target))\n",
    "print(sample_src_mask)\n",
    "print(sample_tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-20 12:22:08,664 INFO pre_trained_vector_mean = 0.002008178, pre_trained_vector_std = 0.43602833\n",
      "2019-01-20 12:22:08,665 INFO Normalizing embeddings...\n",
      "2019-01-20 12:22:08,810 INFO pre_trained_vector_mean = -1.2933846e-08, pre_trained_vector_std = 1.0000006\n"
     ]
    }
   ],
   "source": [
    "pre_trained_vector, embz_size, padding_idx = embedding_param(SAMPLE_DATA_PATH, TEXT, pre_trained_vector_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    embz_size,\n",
    "    vocab_size,\n",
    "    padding_idx,\n",
    "    pre_trained_vector,\n",
    "    stack_number,\n",
    "    heads_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-20 12:22:24,865 INFO Start traning\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n",
      "torch.Size([64, 80, 200]) torch.Size([64, 80, 200]) torch.Size([64, 80, 200])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-a77843c03db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/senior/code/my-transformer/optimize.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, batch_iter, iters, optimizer, criterion, print_every)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Iteration: {i}, loss: {loss}, estimated remaining time: {rem_str}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mrun_one_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/senior/code/my-transformer/optimize.py\u001b[0m in \u001b[0;36mrun_one_train\u001b[0;34m(model, batch_tuple, optimizer, criterion)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# optimizer.zero_grad() already included\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/sum/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/sum/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = get_default_optimizer(model)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "train(model, train_iter, 5000, optimizer, criterion, print_every=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sum]",
   "language": "python",
   "name": "conda-env-sum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
